# Savage Summit Indexer

A real-time Starknet event indexer that streams on-chain game events from the Savage Summit contracts into PostgreSQL. Built on [Apibara DNA](https://www.apibara.com/) for low-latency event streaming and [Drizzle ORM](https://orm.drizzle.team/) for type-safe database access.

For game mechanics, contract addresses, and overall project architecture, see the [top-level README](../README.md).
For AI agents: see [AGENTS.md](AGENTS.md) for implementation guidance.

---

## Table of Contents

- [Overview](#overview)
- [Prerequisites](#prerequisites)
- [Getting Started](#getting-started)
- [Project Structure](#project-structure)
- [Architecture](#architecture)
- [Database Schema](#database-schema)
- [Commands](#commands)
- [Environment Variables](#environment-variables)
- [Testing](#testing)
- [Cross-Layer Sync](#cross-layer-sync)
- [Deployment](#deployment)

---

## Overview

The indexer monitors five Starknet contracts and processes 14 distinct event types into 12 PostgreSQL tables. It powers the game's API and client by maintaining a queryable, real-time mirror of all on-chain state.

**What it does:**

1. Connects to an Apibara DNA stream filtered to the Summit game contracts
2. Decodes raw Starknet events (including packed `felt252` bit fields)
3. Detects derived events by comparing pre- and post-transaction state (stat upgrades, summit ownership changes)
4. Writes processed data to PostgreSQL in idempotent bulk inserts
5. Publishes real-time notifications via `PG NOTIFY` for downstream consumers (API WebSockets)

**Indexed contracts:**

| Contract        | Events                                                                                           |
|-----------------|--------------------------------------------------------------------------------------------------|
| Summit          | BeastUpdatesEvent, LiveBeastStatsEvent, BattleEvent, RewardsEarnedEvent, RewardsClaimedEvent, PoisonEvent, QuestRewardsClaimedEvent, CorpseEvent, SkullEvent |
| Beast NFT       | Transfer                                                                                         |
| Dojo World      | StoreSetRecord (EntityStats), StoreSetRecord (CollectableEntity)                                 |
| Corpse Token    | CorpseEvent                                                                                      |
| Skull Token     | SkullEvent                                                                                       |

---

## Prerequisites

- **Node.js 22** (LTS recommended)
- **pnpm 10** -- package manager for all TypeScript projects in this monorepo
- **PostgreSQL** -- any recent version (14+); the indexer creates its own tables via migrations
- **Apibara DNA stream access** -- a running DNA node or a hosted stream URL

---

## Getting Started

### 1. Install dependencies

```bash
cd indexer
pnpm install
```

### 2. Set up the database

Create a PostgreSQL database and set the connection string:

```bash
export DATABASE_URL="postgres://postgres:postgres@localhost:5432/summit"
```

Run the Drizzle migrations to create all tables, indexes, and PG NOTIFY triggers:

```bash
pnpm db:migrate
```

### 3. Set the stream URL

```bash
export STREAM_URL="<your-apibara-dna-stream-url>"
```

### 4. Start indexing

For local development with hot reload:

```bash
pnpm dev
```

For production:

```bash
pnpm build
pnpm start
```

The indexer begins streaming from block **6,767,900** (the earliest block containing relevant Dojo events) and processes all blocks forward. On first run, this historical sync may take some time depending on stream throughput.

---

## Project Structure

```
indexer/
  apibara.config.ts              # Stream configuration: contract addresses, starting block, env vars
  drizzle.config.ts              # Drizzle Kit configuration for migrations
  Dockerfile                     # Multi-stage production build (Node 22 Alpine)
  package.json                   # Scripts and dependencies
  tsconfig.json                  # TypeScript configuration
  vitest.config.ts               # Test runner configuration
  indexers/
    summit.indexer.ts             # Main indexer: event filtering, decoding, processing, DB writes (~1,889 lines)
  src/
    lib/
      schema.ts                  # Drizzle ORM schema: 12 tables with indexes and constraints
      decoder.ts                 # Event decoders, bit unpacking for LiveBeastStats, selector constants
      decoder.test.ts            # Unit tests for decoders and bit unpacking
  migrations/
    0000_tables.sql              # Generated by Drizzle Kit: all tables and indexes
    0001_triggers.sql            # Hand-written: PG NOTIFY trigger functions (not generated by Drizzle)
  scripts/
    check-dna-status.ts          # Pre-start connectivity check for DNA stream
    test-live-beast-stats-parity.ts  # Cross-layer parity validation against contract constants
```

---

## Architecture

The indexer follows a single-pass pipeline for each block received from the DNA stream:

```
DNA Stream
    |
    v
Filter (5 contract addresses)
    |
    v
Pre-scan token IDs (collect all beast IDs referenced in the block)
    |
    v
Batch context lookups (fetch current DB state for referenced beasts)
    |
    v
Process events (decode, transform, detect derived events)
    |
    v
Bulk inserts (one query per table per block)
    |
    v
PG NOTIFY (real-time push to API layer)
```

### Key Design Decisions

**Single indexer file.** All five contracts are processed in a single indexer (`summit.indexer.ts`) rather than separate indexers per contract. This ensures data consistency -- for example, a `Transfer` event and a `BattleEvent` in the same block are processed together, so ownership lookups during battle processing always reflect the latest state.

**Batch processing.** Events within a block are collected into arrays and written with a single bulk insert per table. This minimizes round trips to PostgreSQL and keeps write latency proportional to the number of tables, not the number of events.

**Idempotency.** Every table insert uses conflict handling:
- **Append-only tables** (battles, rewards_earned, etc.) use `onConflictDoNothing` with unique indexes on `(block_number, transaction_hash, event_index)`. Re-indexing the same block is a no-op.
- **State tables** (beast_stats, beast_owners, etc.) use `onConflictDoUpdate` on their natural key (`token_id` or `entity_hash`). Re-indexing overwrites with identical data.

**Derived events.** Some events are not emitted by the contracts but are inferred by comparing beast state before and after processing. For example, stat upgrades (spirit, luck, specials) and summit ownership changes are detected by diffing the pre-scan snapshot against post-processing state. These derived events are written to the `summit_log` table for the activity feed.

**Real-time push.** Two PostgreSQL trigger functions in `migrations/0001_triggers.sql` publish notifications:
- `summit_update` -- fires on `beast_stats` insert/update when `current_health > 0`, carrying the full beast state plus metadata
- `summit_log_insert` -- fires on every `summit_log` insert, carrying the log entry for activity feeds

The API layer (`api/`) listens on these channels and forwards updates to connected WebSocket clients via the `SubscriptionHub`.

### Bit-Packed Data

The `LiveBeastStats` struct is packed into a single `felt252` (251 bits) on-chain for gas efficiency. The indexer's `decoder.ts` unpacks this using bitwise operations mirroring the Cairo contract layout:

```
Low 128 bits:   last_death_timestamp(64) | rewards_earned(32) | rewards_claimed(32)
High 123 bits:  token_id(17) | current_health(12) | bonus_health(11) | bonus_xp(15)
                | attack_streak(4) | revival_count(6) | extra_lives(12)
                | summit_held_seconds(23) | spirit(8) | luck(8)
                | specials(1) | wisdom(1) | diplomacy(1)
                | captured_summit(1) | used_revival_potion(1) | used_attack_potion(1)
                | max_attack_streak(1)
```

---

## Database Schema

All 12 tables are defined in `src/lib/schema.ts` using Drizzle ORM. Every table includes a UUID primary key (required by the Apibara Drizzle plugin for reorg handling).

### State Tables (upsert)

These tables maintain the current state of an entity. Rows are created on first encounter and updated on subsequent events.

| Table                  | Key           | Description                                           |
|------------------------|---------------|-------------------------------------------------------|
| `beast_stats`          | `token_id`    | Current beast state: health, XP, upgrades, quest flags, rewards |
| `beast_owners`         | `token_id`    | Current NFT owner address, updated on each Transfer   |
| `beasts`               | `token_id`    | Immutable NFT metadata (species, prefix, suffix, level, visual traits); inserted once |
| `beast_data`           | `entity_hash` | Dojo event data: adventurers killed, last death timestamp |
| `skulls_claimed`       | `beast_token_id` | Cumulative skull count per beast                   |
| `quest_rewards_claimed`| `beast_token_id` | Cumulative quest reward amount per beast           |

### Event Tables (append-only)

These tables store an immutable history of game events. Each row has a unique index on `(block_number, transaction_hash, event_index)` for idempotent re-indexing. Exception: `corpse_events` adds `adventurer_id` as a fourth column in its unique index because a single event can produce multiple corpse rows.

| Table              | Description                                              |
|--------------------|----------------------------------------------------------|
| `battles`          | Combat history: attacker, defender, damage breakdown, potions used, XP gained |
| `rewards_earned`   | Reward distribution events per beast                     |
| `rewards_claimed`  | Player reward claim events with u256 amounts             |
| `poison_events`    | Poison attack events with count and player               |
| `corpse_events`    | Corpse collection events with adventurer IDs             |
| `summit_log`       | Unified activity feed with JSON data; includes both direct and derived events |

### Timestamps

Most tables carry three timestamps:

| Column        | Source     | Description                                    |
|---------------|------------|------------------------------------------------|
| `created_at`  | Starknet   | Block timestamp from the Starknet chain        |
| `indexed_at`  | DNA        | When the Apibara DNA stream delivered the block |
| `inserted_at` | PostgreSQL | When the row was inserted (set by `DEFAULT now()`) |

### Schema Management

All schema changes follow the Drizzle Kit workflow:

1. Modify `src/lib/schema.ts`
2. Generate a migration: `pnpm db:generate`
3. Apply the migration: `pnpm db:migrate`

The PG NOTIFY triggers in `migrations/0001_triggers.sql` are hand-written and not managed by Drizzle Kit. Edit that file directly when trigger logic needs to change.

To browse the database interactively:

```bash
pnpm db:studio
```

---

## Commands

| Command               | Description                                                  |
|-----------------------|--------------------------------------------------------------|
| `pnpm dev`            | Start the indexer in development mode with hot reload (`apibara dev`) |
| `pnpm build`          | Build the indexer for production (`apibara build`)           |
| `pnpm start`          | Start the production indexer (`apibara start`)               |
| `pnpm test`           | Run unit tests with Vitest                                   |
| `pnpm test:coverage`  | Run tests with V8 coverage (outputs to `coverage/`)          |
| `pnpm test:parity`    | Run LiveBeastStats cross-layer parity validation             |
| `pnpm check-dna`      | Check DNA stream connectivity and status                     |
| `pnpm db:generate`    | Generate Drizzle migration from schema changes               |
| `pnpm db:migrate`     | Apply pending Drizzle migrations                             |
| `pnpm db:studio`      | Open Drizzle Studio (interactive database browser)           |

Type-checking without emitting files (used in CI):

```bash
pnpm exec tsc --noEmit
```

---

## Environment Variables

| Variable       | Required | Description                                 | Default                                                |
|----------------|----------|---------------------------------------------|--------------------------------------------------------|
| `DATABASE_URL` | Yes      | PostgreSQL connection string                | `postgres://postgres:postgres@localhost:5432/summit` (local); Dockerfile default uses hostname `postgres` |
| `STREAM_URL`   | Yes      | Apibara DNA stream URL                      | None                                                   |
| `DNA_TOKEN`    | No       | Auth token if your stream provider requires it | None                                                 |

The Dockerfile sets a default `STREAM_URL` of `https://mainnet.starknet.a5a.ch` for container builds.

Contract addresses and the starting block are configured in `apibara.config.ts`, not through environment variables. The RPC URL for fetching beast metadata is also set there (defaults to `https://api.cartridge.gg/x/starknet/mainnet/rpc/v0_10`).

---

## Testing

### Unit Tests

Decoder logic and bit unpacking are tested with Vitest:

```bash
pnpm test
```

Tests cover packing and unpacking of `LiveBeastStats` and `QuestRewardsClaimed` across boundary values (zero, max, mixed) and individual flag isolation.

### Coverage

```bash
pnpm test:coverage
```

Coverage reports are generated in LCOV and text formats under `coverage/`. The CI pipeline uploads results to Codecov.

### Parity Tests

See the [Cross-Layer Sync](#cross-layer-sync) section below.

---

## Cross-Layer Sync

The `LiveBeastStats` bit layout is defined in three places that must stay in sync:

| Layer     | File                                          | Role                |
|-----------|-----------------------------------------------|---------------------|
| Contracts | `contracts/src/models/beast.cairo`            | Canonical packing   |
| Indexer   | `indexer/src/lib/decoder.ts`                  | Unpacking for DB    |
| Client    | `client/src/utils/translation.ts`             | Unpacking for UI    |

A cross-layer parity constant is embedded in the Cairo contract. Both the indexer and client have parity scripts that pack known test values and compare the result against this constant:

```bash
pnpm test:parity
```

This script (`scripts/test-live-beast-stats-parity.ts`) runs the following validations:

- **Cross-layer constant** -- packs a known `LiveBeastStats` struct and asserts the packed hex matches the constant from the Cairo contract
- **Round-trip correctness** -- packs and unpacks zero, max, mixed, and flag-isolated vectors
- **Quest rewards** -- packs and unpacks `QuestRewardsClaimed` across boundary values

**Rule:** Any change to the bit layout or field order in `beast.cairo` must update `decoder.ts`, `translation.ts`, and both parity scripts in the same pull request. The CI pipeline triggers indexer and client builds whenever `contracts/src/models/beast.cairo` changes.

---

## Deployment

The indexer ships as a Docker image built from the `Dockerfile` in this directory.

### Docker Build

```bash
docker build -t summit-indexer .
```

### Image Details

- **Base image:** `node:22-alpine` (multi-stage build)
- **Build stage:** Installs all dependencies, runs `apibara build`
- **Production stage:** Installs only production dependencies plus `tsx` (for the pre-start status check script), copies built artifacts
- **Security:** Runs as a non-root `indexer` user (UID 1001)
- **Healthcheck:** Verifies the Node.js process is responsive every 30 seconds (60-second startup grace period)

**Note:** The Dockerfile uses `npm` (with `package-lock.json`) for container builds, while local development uses `pnpm`. Both lockfiles are maintained in the repository.

### Runtime

```bash
docker run \
  -e DATABASE_URL="postgres://user:pass@host:5432/summit" \
  -e STREAM_URL="<your-apibara-dna-stream-url>" \
  summit-indexer
```

On startup, the container runs `check-dna-status.ts` to verify connectivity to the DNA stream before launching the indexer with `--indexer=summit`. If the DNA server is unreachable, the container exits with a non-zero status.

### CI Pipeline

The CI pipeline for the indexer runs on changes to `indexer/**` or `contracts/src/models/beast.cairo`:

```
tsc --noEmit -> apibara build -> parity test -> test:coverage -> Codecov upload
```

All steps must pass before a pull request can merge.
